# -*- coding: utf-8 -*-
"""Iris flower classification internship task 1 for oasis infobyte

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OkfQ5LQqrK59lIze42-q_flwbG2mho8f
"""

#Importing all the necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#Reading the dataset into the pandas dataframe
df = pd.read_csv("/content/Iris.csv")
df

#To get all the information related to the dataset
df.info()

#To view the summary statistics of the dataset
df.describe()

#To check if there are any null values in the dataset. There are no null values in the dataset
df.isnull().sum()

#To check if there are any duplicates in the dataset. There are no duplicates in the dataset
df.duplicated().sum()

#We can draw boxplots to identify outliers. The SepalWidthCm has some outliers.
try:
    for i in df:
        sns.boxplot(df[i])
        plt.show()
except:
    Exception
    print('CATEGORICAL')

# We can remove the outlier using interquartile range
q1 = df["SepalWidthCm"].quantile(0.25)
q3 = df["SepalWidthCm"].quantile(0.75)

IQR = q3 - q1

IQR = 1.5*IQR

ul = q3 + IQR

ll = q1 - IQR

df = df[(df.SepalWidthCm>ll) & (df.SepalWidthCm<ul)]

#As you can see all the outliers has been removed.
try:
    for i in df:
        sns.boxplot(df[i])
        plt.show()
except:
    Exception
    print('CATEGORICAL')

#We can split the dataset for model creation
X= df[['Id','SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]
y = df["Species"]

X

y

# Perform the train test split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)

#I'm using logictic Regression
from sklearn.linear_model import LogisticRegression
Lr = LogisticRegression()

Lr.fit(X_train,y_train)

# Now the model can make prediction
pred = Lr.predict(X)
scores = pd.DataFrame({'Actual':y,'Predictions':pred})

# We can compare the Actual and predictions using table given below
scores.head()

y_test_cap = Lr.predict(X_test)

#Model Evaluation
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test,y_test_cap)*100,'%')